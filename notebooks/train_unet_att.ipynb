{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training Notebook for Attention UNet\n","### See train_unet.ipynb for more details (The training notebooks follow similar structure)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["import sys\n","import os\n","sys.path.append(\"../\")\n","\n","if \"notebook\" in os.getcwd():\n","    os.chdir(\"../\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import traceback\n","import gc\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, random_split\n","from src.data.waveform_data import WaveformDataset\n","from skopt import gp_minimize\n","from skopt.space import Real, Integer, Categorical\n","from skopt.utils import use_named_args\n","from src.models.waveform.cicada_unet_att import CicadaUNetAttModel\n","\n","model = CicadaUNetAttModel()\n","\n","NOISY_DATA_PATH = f\"data/processed/28spk/combined_noisy_waves.pt\"\n","CLEAN_DATA_PATH = f\"data/processed/28spk/combined_clean_waves.pt\"\n","\n","batch_size = 32\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.manual_seed(42) #Consistent results\n","\n","HYPER_OPT = False #Enable for Bayesian Hyperparameter Sweeps\n","f = 0.25 if HYPER_OPT else 1\n","num_epochs = 10 if HYPER_OPT else 30\n","lr = 1e-4 if HYPER_OPT else 0.0002848026275422517\n","\n","print(num_epochs, lr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["data = WaveformDataset(NOISY_DATA_PATH, CLEAN_DATA_PATH, fraction=f)\n","\n","train_size = int(0.8 * len(data))\n","val_size = int(0.15 * len(data))\n","test_size = len(data) - train_size - val_size  # Ensure all samples are used\n","\n","train_set, val_set, test_set = random_split(data, [train_size, val_size, test_size])\n","print(f\"Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n","\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["noisy_batch, clean_batch = next(iter(train_loader))\n","print(noisy_batch.shape, clean_batch.shape)  # Expected: [32, 1, 262144]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["\n","def count_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    \n","    print(f\"Total Parameters: {total_params:,}\")\n","    print(f\"Trainable Parameters: {trainable_params:,}\")\n","\n","    return total_params, trainable_params\n","count_parameters(model)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["t_losses = []\n","v_losses = []\n","snrs = []\n","\n","def compute_snr(clean, estimate):\n","    noise = clean - estimate\n","    snr = 10 * torch.log10(torch.sum(clean ** 2) / torch.sum(noise ** 2))\n","    return snr.item()\n","    \n","def train(model, train_loader, val_loader, num_epochs=num_epochs, lr=1e-4, n_encoders=None, s=None, k=None, \n","          num_heads=None, hidden_channels=None, d=None, device=device):\n","    model = CicadaUNetAttModel(n_encoders=n_encoders, s=s, k=k, num_heads=num_heads, hidden_channels=hidden_channels, d=d)\n","    model.to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    best_snr = 0\n","\n","    for epoch in range(num_epochs):\n","\n","        # Training\n","        print(\"Training ... \")\n","        model.train()\n","        train_loss = 0.0\n","        for noisy, clean in tqdm(train_loader):\n","            noisy, clean = noisy.to(device), clean.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(noisy)\n","            sample_loss = criterion(outputs, clean)\n","            sample_loss.backward()\n","            optimizer.step()\n","\n","            train_loss += sample_loss.item() * noisy.size(0)\n","        \n","        train_loss /= len(train_loader.dataset)\n","\n","        #Validation\n","        print(\"Evaluating ... \")\n","        model.eval()\n","        val_loss = 0.0\n","        total_snr_improvement = 0\n","        with torch.no_grad():  # No gradient computation\n","            for noisy, clean in tqdm(val_loader):\n","                noisy, clean = noisy.to(device), clean.to(device)\n","\n","                outputs = model(noisy)\n","                loss = criterion(outputs, clean)\n","                val_loss += loss.item() * noisy.size(0)\n","\n","                #Computer SNR for evaluation\n","                snr_noisy = compute_snr(clean, noisy)\n","                snr_output = compute_snr(clean, outputs)\n","\n","                # Compute SNR improvement\n","                snr_improvement = snr_output - snr_noisy\n","                total_snr_improvement += snr_improvement * noisy.size(0)\n","\n","            val_loss /= len(val_loader.dataset)  # Average loss\n","            avg_snr_improvement = total_snr_improvement / len(val_loader.dataset)\n","            if avg_snr_improvement > best_snr:\n","                best_snr = avg_snr_improvement\n","                if not HYPER_OPT:\n","                    torch.save(model.state_dict(), f\"ckpts/cicadence_unet_att_epoch_{epoch}.pt\")\n","                \n","        t_losses.append(train_loss)\n","        v_losses.append(val_loss)\n","        snrs.append(avg_snr_improvement)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | SNR Improvement: {avg_snr_improvement:.2f} dB\")\n","\n","    print(\"Training Complete!\")\n","    if HYPER_OPT:\n","        return val_loss\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["def objective(params):\n","    n_encoders = params[0]\n","    s_start = params[1]\n","    kernel = params[2]\n","    lr = params[3]\n","    num_heads = params[4]\n","    hidden_channels = params[5]\n","    d = params[6]\n","    offsets = params[7:]\n","    s = [1]\n","    for i in range(n_encoders):\n","        s.append(s_start)\n","        if s_start * 2 - offsets[i] <= s_start:\n","            s_start *= 2\n","        else:\n","            s_start = s_start * 2 - offsets[i]\n","    k = [kernel for i in range(n_encoders)]\n","    return train(model, train_loader, val_loader, num_epochs=num_epochs, lr=lr, n_encoders=n_encoders, s=s, k=k, \n","                 num_heads=num_heads, hidden_channels=hidden_channels, d=d)\n","    \n","if HYPER_OPT:\n","    space = [\n","        Integer(5, 8, name='n_encoders'),\n","        Integer(2, 16, name='s_start'),    # Starting hidden size\n","        Categorical([3, 5, 7], name='kernel_size'),\n","        Real(1e-5, 1e-3, prior='log-uniform', name='learning_rate'),\n","        Integer(2, 8, name='num_heads'),\n","        Real(0.3, 0.7, prior='uniform', name='hidden_channels'),\n","        Real(0.1, 0.4, prior='uniform', name='dropout'),\n","        *[Integer(1, 10, name=f's_step{i}') for i in range(1, 11)]\n","    ]\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["try:\n","    if HYPER_OPT:\n","        results = gp_minimize(objective, space, n_calls=25, random_state=42)\n","        print(\"Best hyperparameters:\")\n","        for dim, val in zip(space, results.x):\n","            print(f\"{dim.name}: {val}\")\n","    else:\n","        print(\"ACTUALLY TRAINING\")\n","        train(model, train_loader, val_loader, num_epochs=num_epochs, lr=lr, device=device)\n","except Exception as e:\n","    print(e)\n","    traceback.print_exc()\n","finally:\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["print(t_losses)\n","print(v_losses)\n","print(snrs)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6837736,"sourceId":11002768,"sourceType":"datasetVersion"},{"datasetId":6837748,"sourceId":11003356,"sourceType":"datasetVersion"},{"datasetId":6896027,"sourceId":11066583,"sourceType":"datasetVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"ActualAudioENV","language":"python","name":"audioenv"}},"nbformat":4,"nbformat_minor":4}
